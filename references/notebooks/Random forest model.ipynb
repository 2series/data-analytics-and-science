{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "- year: 2016 for all data points\n",
    "- month: number for month of the year\n",
    "- day: number for day of the year\n",
    "- week: day of the week as a character string\n",
    "- temp_2: max temperature 2 days prior\n",
    "- temp_1: max temperature 1 day prior\n",
    "- average: historical average max temperature\n",
    "- actual: max temperature measurement\n",
    "- friend: your friend’s prediction, a random number between 20 below the average and 20 above the average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>week</th>\n",
       "      <th>temp_2</th>\n",
       "      <th>temp_1</th>\n",
       "      <th>average</th>\n",
       "      <th>actual</th>\n",
       "      <th>forecast_noaa</th>\n",
       "      <th>forecast_acc</th>\n",
       "      <th>forecast_under</th>\n",
       "      <th>friend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Fri</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>45.6</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Sat</td>\n",
       "      <td>44</td>\n",
       "      <td>45</td>\n",
       "      <td>45.7</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sun</td>\n",
       "      <td>45</td>\n",
       "      <td>44</td>\n",
       "      <td>45.8</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>Mon</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>45.9</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>Tues</td>\n",
       "      <td>41</td>\n",
       "      <td>40</td>\n",
       "      <td>46.0</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  week  temp_2  temp_1  average  actual  forecast_noaa  \\\n",
       "0  2016      1    1   Fri      45      45     45.6      45             43   \n",
       "1  2016      1    2   Sat      44      45     45.7      44             41   \n",
       "2  2016      1    3   Sun      45      44     45.8      41             43   \n",
       "3  2016      1    4   Mon      44      41     45.9      40             44   \n",
       "4  2016      1    5  Tues      41      40     46.0      44             46   \n",
       "\n",
       "   forecast_acc  forecast_under  friend  \n",
       "0            50              44      29  \n",
       "1            50              44      61  \n",
       "2            46              47      56  \n",
       "3            48              46      53  \n",
       "4            46              46      41  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "features = pd.read_csv('data/temps.csv')\n",
    "features.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify Anomalies / Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of our features is: (348, 12)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of our features is:', features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>temp_2</th>\n",
       "      <th>temp_1</th>\n",
       "      <th>average</th>\n",
       "      <th>actual</th>\n",
       "      <th>forecast_noaa</th>\n",
       "      <th>forecast_acc</th>\n",
       "      <th>forecast_under</th>\n",
       "      <th>friend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>348.0</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "      <td>348.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.477011</td>\n",
       "      <td>15.514368</td>\n",
       "      <td>62.652299</td>\n",
       "      <td>62.701149</td>\n",
       "      <td>59.760632</td>\n",
       "      <td>62.543103</td>\n",
       "      <td>57.238506</td>\n",
       "      <td>62.373563</td>\n",
       "      <td>59.772989</td>\n",
       "      <td>60.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.498380</td>\n",
       "      <td>8.772982</td>\n",
       "      <td>12.165398</td>\n",
       "      <td>12.120542</td>\n",
       "      <td>10.527306</td>\n",
       "      <td>11.794146</td>\n",
       "      <td>10.605746</td>\n",
       "      <td>10.549381</td>\n",
       "      <td>10.705256</td>\n",
       "      <td>15.626179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>44.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>49.975000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>47.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>58.200000</td>\n",
       "      <td>62.500000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>69.025000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>71.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016.0</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>77.400000</td>\n",
       "      <td>92.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>79.000000</td>\n",
       "      <td>95.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         year       month         day      temp_2      temp_1     average  \\\n",
       "count   348.0  348.000000  348.000000  348.000000  348.000000  348.000000   \n",
       "mean   2016.0    6.477011   15.514368   62.652299   62.701149   59.760632   \n",
       "std       0.0    3.498380    8.772982   12.165398   12.120542   10.527306   \n",
       "min    2016.0    1.000000    1.000000   35.000000   35.000000   45.100000   \n",
       "25%    2016.0    3.000000    8.000000   54.000000   54.000000   49.975000   \n",
       "50%    2016.0    6.000000   15.000000   62.500000   62.500000   58.200000   \n",
       "75%    2016.0   10.000000   23.000000   71.000000   71.000000   69.025000   \n",
       "max    2016.0   12.000000   31.000000  117.000000  117.000000   77.400000   \n",
       "\n",
       "           actual  forecast_noaa  forecast_acc  forecast_under      friend  \n",
       "count  348.000000     348.000000    348.000000      348.000000  348.000000  \n",
       "mean    62.543103      57.238506     62.373563       59.772989   60.034483  \n",
       "std     11.794146      10.605746     10.549381       10.705256   15.626179  \n",
       "min     35.000000      41.000000     46.000000       44.000000   28.000000  \n",
       "25%     54.000000      48.000000     53.000000       50.000000   47.750000  \n",
       "50%     62.500000      56.000000     61.000000       58.000000   60.000000  \n",
       "75%     71.000000      66.000000     72.000000       69.000000   71.000000  \n",
       "max     92.000000      77.000000     82.000000       79.000000   95.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Descriptive statistics for each column\n",
    "features.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Unfortunately, we aren’t quite at the point where you can just feed raw data into a model and have it return an answer (although people are working on this)! We will need to do some minor modification to put our data into machine-understandable terms. We will use the Python library Pandas for our data manipulation relying, on the structure known as a dataframe, which is basically an excel spreadsheet with rows and columns.\n",
    "\n",
    "The exact steps for preparation of the data will depend on the model used and the data gathered, but some amount of data manipulation will be required for any machine learning application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Hot Encoding\n",
    "The first step for us is known as one-hot encoding of the data. This process takes categorical variables, such as days of the week and converts it to a numerical representation without an arbitrary ordering. Days of the week are intuitive to us because we use them all the time. You will (hopefully) never find anyone who doesn’t know that ‘Mon’ refers to the first day of the workweek, but machines do not have any intuitive knowledge. What computers know is numbers and for machine learning we must accommodate them. We could simply map days of the week to numbers 1–7, but this might lead to the algorithm placing more importance on Sunday because it has a higher numerical value. Instead, we change the single column of weekdays into seven columns of binary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>average</th>\n",
       "      <th>actual</th>\n",
       "      <th>forecast_noaa</th>\n",
       "      <th>forecast_acc</th>\n",
       "      <th>forecast_under</th>\n",
       "      <th>friend</th>\n",
       "      <th>week_Fri</th>\n",
       "      <th>week_Mon</th>\n",
       "      <th>week_Sat</th>\n",
       "      <th>week_Sun</th>\n",
       "      <th>week_Thurs</th>\n",
       "      <th>week_Tues</th>\n",
       "      <th>week_Wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45.6</td>\n",
       "      <td>45</td>\n",
       "      <td>43</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.7</td>\n",
       "      <td>44</td>\n",
       "      <td>41</td>\n",
       "      <td>50</td>\n",
       "      <td>44</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45.8</td>\n",
       "      <td>41</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>47</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45.9</td>\n",
       "      <td>40</td>\n",
       "      <td>44</td>\n",
       "      <td>48</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46.0</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   average  actual  forecast_noaa  forecast_acc  forecast_under  friend  \\\n",
       "0     45.6      45             43            50              44      29   \n",
       "1     45.7      44             41            50              44      61   \n",
       "2     45.8      41             43            46              47      56   \n",
       "3     45.9      40             44            48              46      53   \n",
       "4     46.0      44             46            46              46      41   \n",
       "\n",
       "   week_Fri  week_Mon  week_Sat  week_Sun  week_Thurs  week_Tues  week_Wed  \n",
       "0         1         0         0         0           0          0         0  \n",
       "1         0         0         1         0           0          0         0  \n",
       "2         0         0         0         1           0          0         0  \n",
       "3         0         1         0         0           0          0         0  \n",
       "4         0         0         0         0           0          1         0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# One-hot encode the data using pandas get_dummies\n",
    "features = pd.get_dummies(features)\n",
    "\n",
    "# Display the first 5 rows of the last 12 columns\n",
    "features.iloc[:,5:].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features and Targets and Convert Data to Arrays\n",
    "\n",
    "Now, we need to separate the data into the features and targets. The target, also known as the label, is the value we want to predict, in this case the actual max temperature and the features are all the columns the model uses to make a prediction. We will also convert the Pandas dataframes to Numpy arrays because that is the way the algorithm works. (I save the column headers, which are the names of the features, to a list to use for later visualization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use numpy to convert to arrays\n",
    "import numpy as np\n",
    "\n",
    "# Labels are the values we want to predict\n",
    "labels = np.array(features['actual'])\n",
    "\n",
    "# Remove the labels from the features\n",
    "# axis 1 refers to the columns\n",
    "features= features.drop('actual', axis = 1)\n",
    "\n",
    "# Saving feature names for later use\n",
    "feature_list = list(features.columns)\n",
    "\n",
    "# Convert to numpy array\n",
    "features = np.array(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Testing Sets\n",
    "\n",
    "There is one final step of data preparation: splitting data into training and testing sets. During training, we let the model ‘see’ the answers, in this case the actual temperature, so it can learn how to predict the temperature from the features. We expect there to be some relationship between all the features and the target value, and the model’s job is to learn this relationship during training. Then, when it comes time to evaluate the model, we ask it to make predictions on a testing set where it only has access to the features (not the answers)! Because we do have the actual answers for the test set, we can compare these predictions to the true value to judge how accurate the model is. Generally, when training a model, we randomly split the data into training and testing sets to get a representation of all data points (if we trained on the first nine months of the year and then used the final three months for prediction, our algorithm would not perform well because it has not seen any data from those last three months.) I am setting the random state to 42 which means the results will be the same each time I run the split for reproducible results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Skicit-learn to split data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(features, labels, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look at the shape of all the data to make sure we did everything correctly. We expect the training features number of columns to match the testing feature number of columns and the number of rows to match for the respective training and testing features and the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features Shape: (261, 17)\n",
      "Training Labels Shape: (261,)\n",
      "Testing Features Shape: (87, 17)\n",
      "Testing Labels Shape: (87,)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features Shape:', train_features.shape)\n",
    "print('Training Labels Shape:', train_labels.shape)\n",
    "print('Testing Features Shape:', test_features.shape)\n",
    "print('Testing Labels Shape:', test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as if everything is in order!  \n",
    "Just to recap, to get the data into a form acceptable for machine learning we:\n",
    "\n",
    "- One-hot encoded categorical variables\n",
    "- Split data into features and labels\n",
    "- Converted to arrays\n",
    "- Split data into training and testing sets\n",
    "\n",
    "Depending on the initial data set, there may be extra work involved such as removing outliers, [imputing missing values](http://www.stat.columbia.edu/~gelman/arm/missing.pdf), or [converting temporal variables into cyclical representations](http://blog.davidkaleko.com/feature-engineering-cyclical-features.html). These steps may seem arbitrary at first, but once you get the basic workflow, it will be generally the same for any machine learning problem. It’s all about taking human-readable data and putting it into a form that can be understood by a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish Baseline\n",
    "Before we can make and evaluate predictions, we need to establish a baseline, a sensible measure that we hope to beat with our model. If our model cannot improve upon the baseline, then it will be a failure and we should try a different model or admit that machine learning is not right for our problem. The baseline prediction for our case can be the historical max temperature averages. In other words, our baseline is the error we would get if we simply predicted the average max temperature for all days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average baseline error:  5.06\n"
     ]
    }
   ],
   "source": [
    "# The baseline predictions are the historical averages\n",
    "baseline_preds = test_features[:, feature_list.index('average')]\n",
    "\n",
    "# Baseline errors, and display average baseline error\n",
    "baseline_errors = abs(baseline_preds - test_labels)\n",
    "print('Average baseline error: ', round(np.mean(baseline_errors), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our goal! If we can’t beat an average error of 5 degrees, then we need to rethink our approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "After all the work of data preparation, creating and training the model is pretty simple using Scikit-learn. We import the random forest regression model from skicit-learn, instantiate the model, and fit (scikit-learn’s name for training) the model on the training data. (Again setting the random state for reproducible results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the model we are using\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Instantiate model with 1000 decision trees\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Predictions on the Test Set\n",
    "Our model has now been trained to learn the relationships between the features and the targets. The next step is figuring out how good the model is! To do this we make predictions on the test features (the model is never allowed to see the test answers). We then compare the predictions to the known answers. When performing regression, we need to make sure to use the absolute error because we expect some of our answers to be low and some to be high. We are interested in how far away our average prediction is from the actual value so we take the absolute value (as we also did when establishing the baseline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 3.87 degrees.\n"
     ]
    }
   ],
   "source": [
    "# Use the forest's predict method on the test data\n",
    "predictions = rf.predict(test_features)\n",
    "\n",
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our average estimate is off by 3.83 degrees. That is more than a 1 degree average improvement over the baseline. Although this might not seem significant, it is nearly 25% better than the baseline, which, depending on the field and the problem, could represent millions of dollars to a company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine Performance Metrics\n",
    "To put our predictions in perspective, we can calculate an accuracy using the mean average percentage error subtracted from 100 %."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 93.94 %.\n"
     ]
    }
   ],
   "source": [
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good! Our model has learned how to predict the maximum temperature for the next day in Seattle with 94% accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve Model if Necessary\n",
    "In the usual machine learning workflow, this would be when start hyperparameter tuning. This is a complicated phrase that means “adjust the settings to improve performance” (The settings are known as [hyperparameters](https://machinelearningmastery.com/difference-between-a-parameter-and-a-hyperparameter/) to distinguish them from model parameters learned during training). The most common way to do this is simply make a bunch of models with different settings, evaluate them all on the same validation set, and see which one does best. Of course, this would be a tedious process to do by hand, and there are [automated methods](http://scikit-learn.org/stable/modules/grid_search.html) to do this process in Skicit-learn. Hyperparameter tuning is often [more engineering](https://www.oreilly.com/ideas/big-datas-biggest-secret-hyperparameter-tuning) than theory-based, and I would encourage anyone interested to check out the [documentation](http://scikit-learn.org/stable/modules/grid_search.html) and start playing around! An accuracy of 94% is satisfactory for this problem, but keep in mind that the first model built will almost never be the model that makes it to production."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpret Model and Report Results\n",
    "At this point, we know our model is good, but it’s pretty much a [black box](https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/). We feed in some Numpy arrays for training, ask it to make a prediction, evaluate the predictions, and see that they are reasonable. The question is: how does this model arrive at the values? There are two approaches to get under the hood of the random forest: first, we can look at a single tree in the forest, and second, we can look at the feature importances of our explanatory variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This course can be found [here](https://towardsdatascience.com/random-forest-in-python-24d0893d51c0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
